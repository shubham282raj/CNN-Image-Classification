{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_url = \"./CUB_200_2011/images.txt\"\n",
    "train_test_split_url = \"./CUB_200_2011/train_test_split.txt\"\n",
    "classes_url = \"./CUB_200_2011/classes.txt\"\n",
    "image_class_labels_url = \"./CUB_200_2011/image_class_labels.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.genfromtxt(images_url , delimiter=' ', dtype=str) #<image_id> <image_name>\n",
    "image = {int(row[0]): \"CUB_200_2011/images/\"+row[1] for row in image}\n",
    "\n",
    "train_test_split = np.genfromtxt(train_test_split_url, delimiter=\" \", dtype=str) #<image_id> <is_training_image>\n",
    "train_test_split = {int(row[0]): int(row[1]) for row in train_test_split}\n",
    "\n",
    "classes = np.genfromtxt(classes_url, delimiter=\" \", dtype=str) #<class_id> <class_name>\n",
    "classes = {int(row[0]): row[1] for row in classes}\n",
    "\n",
    "image_class_labels = np.genfromtxt(image_class_labels_url, delimiter=\" \", dtype=str).astype(int) #<image_id> <class_id>\n",
    "image_class_labels = {int(row[0]): int(row[1]) for row in image_class_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>image</td>\n",
    "        <td>&lt;image_id&gt; &lt;image_name&gt;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>train_test_split</td>\n",
    "        <td>&lt;image_id&gt; &lt;is_training_image&gt;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>classes</td>\n",
    "        <td>&lt;class_id&gt; &lt;class_name&gt;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>image_class_labels</td>\n",
    "        <td>&lt;image_id&gt; &lt;class_id&gt;</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 5\n",
    "print(row, image[row])\n",
    "print(row, train_test_split[row])\n",
    "print(row, classes[row])\n",
    "print(row, image_class_labels[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train = {key: value for key, value in  train_test_split.items() if value == 1}\n",
    "# image_test = {key: value for key, value in  train_test_split.items() if value == 0}\n",
    "image_train = np.array([key for key, value in train_test_split.items() if value == 1])\n",
    "image_test = np.array([key for key, value in train_test_split.items() if value == 0])\n",
    "\n",
    "n_train = len(image_train)\n",
    "n_test = len(image_test)\n",
    "n_classes = len(classes)\n",
    "\n",
    "print(\"Number of Images:\", len(image))\n",
    "print(f\"n_train: {n_train}\")\n",
    "print(f\"n_test: {n_test}\")\n",
    "print(f\"n_classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>image_train</td>\n",
    "        <td>list of &lt;image_id&gt;</td>\n",
    "        <td>&lt;is_training_image&gt; == 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>image_test</td>\n",
    "        <td>list of &lt;image_id&gt;</td>\n",
    "        <td>&lt;is_training_image&gt; == 0</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    plt.imshow(plt.imread(image))\n",
    "    plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(image[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### EfficientNet_B1_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_out_ftrs = 200 # number of classes for out classification is 200\n",
    "image_input_size = 244 # 244x244 image; imagas are resized to this size\n",
    "batch_size_train = 4\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.1\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(param.numel() for param in model.parameters())\n",
    "print(f\"Total number of parameters in model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers for fine tuning (not doing this takes it very long to train)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# number of inputs in last layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_out_ftrs)\n",
    "\n",
    "# printing the last layer : classifier\n",
    "model.classifier\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset in torch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_input_size,image_input_size)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBDataset(Dataset):\n",
    "    def __init__(self, image_id, id_to_url, image_class_labels, transform):\n",
    "        self.x = [id_to_url[x] for x in image_id]\n",
    "        self.y = [image_class_labels[x] for x in image_id]\n",
    "        self.n_samples = len(image_id)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.x[index])\n",
    "        img = self.transform(img).expand(3,-1,-1)\n",
    "        return img, self.y[index]-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CUBDataset(\n",
    "    image_id=image_train,\n",
    "    id_to_url=image,\n",
    "    image_class_labels=image_class_labels,\n",
    "    transform=transform\n",
    ")\n",
    "dataset_test = CUBDataset(\n",
    "    image_id=image_test,\n",
    "    id_to_url=image,\n",
    "    image_class_labels=image_class_labels,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataloader_train))\n",
    "print(len(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataloader_train)\n",
    "# j = 1\n",
    "# for i in dataloader_train:\n",
    "#     features, labels = next(dataiter)\n",
    "#     # if features.shape != torch.Size([1,3,244,244]):\n",
    "#     features = features.expand(-1,3,244,244).numpy()\n",
    "#     print(features.shape)\n",
    "#     plt.imshow(features.squeeze().transpose(1,2,0))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_steps = len(dataloader_train)\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(\"Training Started\")\n",
    "time_start = time.time()\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(dataloader_train):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_one_hot = torch.softmax(outputs, dim=1).argmax(dim=1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%300 == 0 or i==1498: \n",
    "            print(f\"Epoch {epoch+1}/{num_epoch}, Step {i+1}/{n_total_steps}, Loss {loss.item():.4f}\")\n",
    "            print(f\"\\tModel {output_one_hot.tolist()} Acutal {labels.tolist()} Difference {(output_one_hot-labels).tolist()}\")\n",
    "            # print()\n",
    "    print()\n",
    "time_elapsed = time.time() - time_start\n",
    "print(f\"Training Finished in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"num_epoch_2_all_grad_on.pth\"\n",
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_total_steps = len(dataloader_test)\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, (images, labels) in enumerate(dataloader_test):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        print(predictions, labels)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
