{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_url = \"./CUB_200_2011/images.txt\"\n",
    "train_test_split_url = \"./CUB_200_2011/train_test_split.txt\"\n",
    "classes_url = \"./CUB_200_2011/classes.txt\"\n",
    "image_class_labels_url = \"./CUB_200_2011/image_class_labels.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.genfromtxt(images_url , delimiter=' ', dtype=str) #<image_id> <image_name>\n",
    "\n",
    "train_test_split = np.genfromtxt(train_test_split_url, delimiter=\" \", dtype=str) #<image_id> <is_training_image>\n",
    "\n",
    "classes = np.genfromtxt(classes_url, delimiter=\" \", dtype=str) #<class_id> <class_name>\n",
    "\n",
    "image_class_labels = np.genfromtxt(image_class_labels_url, delimiter=\" \", dtype=str).astype(int) #<image_id> <class_id>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>image</td>\n",
    "        <td>&lt;image_id&gt; &lt;image_name&gt;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>train_test_split</td>\n",
    "        <td>&lt;image_id&gt; &lt;is_training_image&gt;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>classes</td>\n",
    "        <td>&lt;class_id&gt; &lt;class_name&gt;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>image_class_labels</td>\n",
    "        <td>&lt;image_id&gt; &lt;class_id&gt;</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = {int(row[0]): \"CUB_200_2011/images/\"+row[1] for row in image}\n",
    "\n",
    "train_test_split = {int(row[0]): int(row[1]) for row in train_test_split}\n",
    "\n",
    "classes = {int(row[0]): row[1] for row in classes}\n",
    "\n",
    "image_class_labels = {int(row[0]): int(row[1]) for row in image_class_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 5\n",
    "print(row, image[row])\n",
    "print(row, train_test_split[row])\n",
    "print(row, classes[row])\n",
    "print(row, image_class_labels[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train = {key: value for key, value in  train_test_split.items() if value == 1}\n",
    "# image_test = {key: value for key, value in  train_test_split.items() if value == 0}\n",
    "image_train = np.array([key for key, value in train_test_split.items() if value == 1])\n",
    "image_test = np.array([key for key, value in train_test_split.items() if value == 0])\n",
    "\n",
    "image_split = {\n",
    "    \"train\": image_train,\n",
    "    \"test\": image_test\n",
    "}\n",
    "\n",
    "n_train = len(image_train)\n",
    "n_test = len(image_test)\n",
    "n_classes = len(classes)\n",
    "\n",
    "print(\"Number of Images:\", len(image))\n",
    "print(f\"n_train: {n_train}\")\n",
    "print(f\"n_test: {n_test}\")\n",
    "print(f\"n_classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>image_train</td>\n",
    "        <td>list of &lt;image_id&gt;</td>\n",
    "        <td>&lt;is_training_image&gt; == 1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>image_test</td>\n",
    "        <td>list of &lt;image_id&gt;</td>\n",
    "        <td>&lt;is_training_image&gt; == 0</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    plt.imshow(plt.imread(image))\n",
    "    plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showImage(image[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### EfficientNet_B1_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_out_ftrs = 200 # number of classes for out classification is 200\n",
    "image_input_size = 244 # 244x244 image; imagas are resized to this size\n",
    "batch_size = 4\n",
    "# batch_size_test = 1\n",
    "learning_rate = 0.001\n",
    "num_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in original model: {total_params}\")\n",
    "\n",
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f\"Total number of training parameters in original model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers for fine tuning (not doing this takes it very long to train)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# number of inputs in last layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_out_ftrs)\n",
    "\n",
    "# printing the last layer : classifier\n",
    "print(model.classifier)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in fine-tuned model: {total_params}\")\n",
    "\n",
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f\"Total number of training parameters in fine-tuned model: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset in torch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandGrayscales:\n",
    "    def __call__(self, sample):\n",
    "        return sample.expand(3,-1,-1)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_input_size,image_input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        ExpandGrayscales()\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_trasform = transforms.Compose([\n",
    "    transforms.Resize((image_input_size,image_input_size)),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.5,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.05\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    ExpandGrayscales()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBDataset(Dataset):\n",
    "    def __init__(self, image_id, id_to_url, image_class_labels, transform):\n",
    "        self.x = [id_to_url[x] for x in image_id]\n",
    "        self.y = [image_class_labels[x] for x in image_id]\n",
    "        self.n_samples = len(image_id)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.x[index])\n",
    "        img = self.transform(img)\n",
    "        return img, self.y[index]-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_train_dataset = CUBDataset(\n",
    "    image_id=image_split[\"train\"],\n",
    "    id_to_url=image,\n",
    "    image_class_labels=image_class_labels,\n",
    "    transform=augmentation_trasform\n",
    ")\n",
    "\n",
    "augment_batch_size = 20\n",
    "\n",
    "augment_train_dataloader = DataLoader(\n",
    "    dataset=augment_train_dataset,\n",
    "    batch_size=augment_batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = int(time.time())\n",
    "folder_path = \"CUB_200_2011/aug_images\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "\n",
    "    os.makedirs(folder_path)\n",
    "    for _ in range(3):\n",
    "        for images, labels in augment_train_dataloader:\n",
    "            for i in range(images.shape[0]):\n",
    "                file_path = folder_path + \"/\" + str(int(labels[i])+1) + \"_img\" + str(img_num) + \".png\"\n",
    "                save_image(images[i], file_path)\n",
    "                image[img_num] = file_path\n",
    "                image_split[\"train\"] = np.append(image_split[\"train\"], img_num)\n",
    "                image_class_labels[img_num] = (int(labels[i])+1)\n",
    "                img_num += 1\n",
    "\n",
    "else:\n",
    "    file_names = os.listdir(folder_path)\n",
    "    for file_name in file_names:\n",
    "        class_id = int(file_name.split(\"_\")[0])\n",
    "        file_path = folder_path + \"/\" + file_name\n",
    "        image[img_num] = file_path\n",
    "        image_split[\"train\"] = np.append(image_split[\"train\"], img_num)\n",
    "        image_class_labels[img_num] = (class_id)\n",
    "        img_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(image_split[\"train\"])\n",
    "np.random.shuffle(image_split[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(image), len(image_split[\"train\"]), len(image_split[\"test\"]), len(image_class_labels))\n",
    "print(f\"Train + Test: {len(image)}\")\n",
    "print(f\"Train: {len(image_split[\"train\"])}\")\n",
    "print(f\"Test: {len(image_split[\"test\"])}\")\n",
    "print(f\"Image Class Label Length: {len(image_class_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Actual Train / Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    x: CUBDataset(\n",
    "        image_id=image_split[x],\n",
    "        id_to_url=image, \n",
    "        image_class_labels=image_class_labels,\n",
    "        transform=transform\n",
    "    )\n",
    "    for x in [\"train\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    x: DataLoader(\n",
    "        dataset=datasets[x],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    for x in [\"train\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    x: len(datasets[x])\n",
    "    for x in [\"train\", \"test\"]\n",
    "}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_sizes = {\n",
    "    x: len(dataloaders[x])\n",
    "    for x in [\"train\", \"test\"]\n",
    "}\n",
    "dataloader_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataloader_train)\n",
    "# j = 1\n",
    "# for i in dataloader_train:\n",
    "#     features, labels = next(dataiter)\n",
    "#     # if features.shape != torch.Size([1,3,244,244]):\n",
    "#     features = features.expand(-1,3,244,244).numpy()\n",
    "#     print(features.shape)\n",
    "#     plt.imshow(features.squeeze().transpose(1,2,0))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not required in Adam optimizer\n",
    "step_lr_schedular = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=optimizer,\n",
    "    step_size=7,\n",
    "    gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, schedular=None, num_epoch=20, save_checkpoint=False):\n",
    "    print(f\"Training Started on {device}\")\n",
    "    train_time = 0\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch}\", end=\"\")\n",
    "\n",
    "        #each epoch has a training and a validation phase\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            time_start = time.time()\n",
    "\n",
    "            model.train() if phase == \"train\" else model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            for i, (images, labels) in enumerate(dataloaders[phase]):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(images)\n",
    "                    output_one_hot = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training loop\n",
    "                    if phase == \"train\":\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                if phase == \"train\" and (i+1) % int(dataloader_sizes[phase]/10) == 0:\n",
    "                    print(\"-\", end=\" \")\n",
    "                        \n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_corrects += torch.sum(output_one_hot == labels.data)\n",
    "\n",
    "            if schedular != None and phase == \"train\":\n",
    "                    schedular.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = 100 * running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            epoch_time = time.time() - time_start\n",
    "            if phase == \"train\":\n",
    "                train_time += epoch_time\n",
    "\n",
    "            print(f\"\\n{phase} Loss: {epoch_loss:.2f} Acc: {epoch_acc:.2f}%\", f\"Time_Taken: {epoch_time//60:.0f}m {epoch_time%60:.0f}s\", end=\"\")\n",
    "\n",
    "            # deep copy the best model\n",
    "            if phase == \"train\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "    print(f\"Training Finished in {train_time//60:.0f}m {train_time%60:.0f}s\")\n",
    "    print(f\"Best Test Accuracy: {best_acc:4f}\")\n",
    "    print(model.__class__.__name__ + \"_checkpoint_best_acc_\" + str(f\"{best_acc:.4f}\") + \"_\" + \"_epoch_\" + str(num_epoch) + \"_optim_\" + optimizer.__class__.__name__ + \"_criterion_\" + criterion.__class__.__name__)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    if save_checkpoint == True:\n",
    "        checkpoint = {\n",
    "            \"epoch\": num_epoch,\n",
    "            \"criterion\": criterion,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict()\n",
    "        }\n",
    "        file_name = model.__class__.__name__ + \"_checkpoint_best_acc_\" + str(f\"{best_acc:.4f}\") + \"_\" + \"_epoch_\" + str(num_epoch) + \"_optim_\" + optimizer.__class__.__name__ + \"_criterion_\" + criterion.__class__.__name__ + \".pth\"\n",
    "        torch.save(checkpoint, file_name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epoch=num_epoch,\n",
    "    save_checkpoint=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
